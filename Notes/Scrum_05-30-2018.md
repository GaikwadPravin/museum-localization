# Scrum 05/30/2018
## participants: 
Pravin, Sonali, Rosa

## TODO List
* Being Familiar with github process(**Everyone**)
    * Chris will create an assignment on the github for practice. Everyone of you just, 
        1. fork the project to your account
        2. clone to your local computer
        3. do some modification for the file
        4. commit your modification
        5. push back to your repository
        6. create a pull request
        7. (optional) create a new branch on your local code
* **!!!Complete the requirement document before next scrum. As detailed as possible.**
    * **Pravin, Sonali** for Sensor, 3D sound rendering module. Also for the general intro part before all modules
    * **Rosa** for the GUI part. (**Pravin, Sonali** optional)
* **Pravin** will ask Dr. McMullen to get the Slides of project from 17spring/summer 18spring

## Other Notes

* Setting Regular Scrum Time: Monday, Thursday 9:30am EST
    1. Someone should take notes for each scrum. Each meeting notes should be in an individual file like this note. And add a link to the README.md file in this directory
* Q&A about the requirement:
    1. Dashboard is from manufacture, it’s different from the GUI. But info you can get from dashboard is limited through API.
        1. last year location is given by dashboard through UDP api
        2. Suppose to get location from sensor directly to Pi(this year) Sensor->Pi
        3. Rendering sound
            1. ideally should on Pi
            2. if not working, rendering on computer/server, then streaming to Pi
        4. How do they get location
            1. they tried to directly on Pi, but failed. Then they used the UDP api from last year(but that missing the orientation data)
        5. can we get orientation and location directly from dashboard to Pi?
    2. Implement gradually, with hand crafted location first
    3. will they able to render sound from pi
        1. last year, matlab one doesn’t have pi involved 
        2. this year, on their PC version, rendering HRTF works. but when running the same code on Pi, has huge performance issue
    4. Can we get a demo of what they have done
        1. they finished the rendering part from matlab to python

* Suggested breakdown detail task goal
    * rendering sound is **mandatory for each member**
        1. go through the previous code, either matlab or python one. Write your own or convert from theirs, playback a spatial sound effect based on one sound source. In different direction (0, 45, 90, 135, 180). Doing it in a rotate in 1 second gap
        2. include elevation part
        3. (realtime location update)play a sound source continuously, without any breaking/lag(double buffer). 
        4. multiple sound sources
    * GUI part **(Rosa, Pravin)**
        1. add/remove components(button, canvas items, menu items) on the GUI
            1. write your own GUI implementation from scratch 
        2. update these things on canvas realtime
            1. e.g. user moving from left to right with a constant speed, or with a preset route
            2. set the location on the caves for other components(sound source, blocks)
            3. optional(integrate with the other part of the application)
    3. Sensor **(Pravin, Sonali)**
        1. basic settings
            1. set the frequency of the sensor
            2. set the ID of the sensor
            3. restore default settings of the sensor
            4. know how to set mobile beacon of the sensor
            5. if the system failed, know where to ask questions(marvelmind.com bbs)
            6. fire up the system from scratch
            7. know the difference between freeze/unfreeze mode
        2. settings for application
            1. configure the start/zero sensor
            2. set the coordinate orientation(double check the latest implementation)
            3. how to read location/gyro/orientation data from the sensor
                1. make it work on computer first, then pi
            4. translate the raw gyro data to actual app location and orientation
            5. translate the sensor coordinate to room setting coordinate
